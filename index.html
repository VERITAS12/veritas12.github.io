<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hanshi Wang's HomePage | Welcome to Hanshi's HomePage! Appreciate your interest!</title><meta name="author" content="Hanshi Wang"><meta name="copyright" content="Hanshi Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="I am currently a PhD student at NLPR of the Institute of Automation, Chinese Academy of Science (CASIA), under the supervision of Prof. Jin Gao and Prof. Weiming Hu. Prior to that, I received my B.E.">
<meta property="og:type" content="website">
<meta property="og:title" content="Hanshi Wang&#39;s HomePage">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Welcome to Hanshi&#39;s HomePage! Appreciate your interest!">
<meta property="og:description" content="I am currently a PhD student at NLPR of the Institute of Automation, Chinese Academy of Science (CASIA), under the supervision of Prof. Jin Gao and Prof. Weiming Hu. Prior to that, I received my B.E.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/hanshiwang.jpg">
<meta property="article:published_time" content="2025-10-27T03:15:51.875Z">
<meta property="article:modified_time" content="2025-10-27T03:15:51.875Z">
<meta property="article:author" content="Hanshi Wang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/hanshiwang.jpg"><script type="application/ld+json"></script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//vercount.bsz.wiki"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hanshi Wang\'s HomePage',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'page'
}</script><script>
  /* 只改域名，脚本仍用官方 2.3 版本 */
  window.bsz_config = { apiDomain: "vercount.bsz.wiki" };
</script>
<script async src="https://cdn.jsdelivr.net/npm/busuanzi@2.3.0/bsz.pure.mini.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="page" id="body-wrap"><header class="not-home-page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Welcome to Hanshi's HomePage! Appreciate your interest!</span></a></span><div id="menus"></div></nav><div id="page-site-info"><h1 id="site-title">Hanshi Wang's HomePage</h1></div></header><main class="layout" id="content-inner"><div id="page"><div class="container" id="article-container"><p>I am currently a PhD student at <a target="_blank" rel="noopener" href="https://nlpr.ia.ac.cn/en/">NLPR</a> of the Institute of Automation, Chinese Academy of Science (CASIA), under the supervision of <a target="_blank" rel="noopener" href="https://nlpr.ia.ac.cn/users/gaojin/index.htm">Prof. Jin Gao</a> and <a target="_blank" rel="noopener" href="https://people.ucas.ac.cn/~huweiming">Prof. Weiming Hu</a>. Prior to that, I received my B.E. degree from Tianjin University. Notably, I work closely with <a target="_blank" rel="noopener" href="https://zhipengzhang.cn/">Prof.  Zhipeng Zhang</a> through my ongoing internships at <a target="_blank" rel="noopener" href="https://www.shlab.org.cn/">AI School of Shanghai Jiaotong University</a> and <a target="_blank" rel="noopener" href="https://www.kargo-bot.com/">KargoBot</a>. My research focuses on perception, scene understanding, and action planning in autonomous driving and embodied intelligence scenarios.</p>
<h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><h4 id="AutoPrune-Each-Complexity-Deserves-a-Pruning-Policy-NeurIPS-2025-First-Author-Code"><a href="#AutoPrune-Each-Complexity-Deserves-a-Pruning-Policy-NeurIPS-2025-First-Author-Code" class="headerlink" title="AutoPrune: Each Complexity Deserves a Pruning Policy | NeurIPS 2025 | First Author | Code"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.23931">AutoPrune: Each Complexity Deserves a Pruning Policy</a> | NeurIPS 2025 | <em>First Author</em> | <a target="_blank" rel="noopener" href="https://github.com/AutoLab-SAI-SJTU/AutoPrune">Code</a></h4><div style="overflow:auto; margin:24px 0;">
  <!-- 1. 浮动图片 -->
  <img
    src="paper_imgs/AutoPrune.png"
    alt="MambaFusion"
    style="
      float: left;
      width: 200px;
      margin: 0 16px 16px 0;
      object-fit: contain;
    "
  />


<p>  <span style="margin-right:24px;"> <strong>Motivation:</strong> VLMs for vision language and end to end driving suffer from long visual sequences that raise memory and latency, while training free pruning often uses fixed schedules without global compute control, which limits reasoning heavy tasks. <strong>Method:</strong> We propose AutoPrune, a plug and play framework that estimates mutual information between early visual and textual tokens and maps it to a budget constrained logistic retention curve, yielding per sample and per task token keep ratios across layers under any target token or FLOPs budget. <strong>Results:</strong> On LLaVA 1.5 7B and other VLM or VLA models, AutoPrune removes up to 89% visual tokens and cuts FLOPs by 76.8% while retaining 96.7% average accuracy, surpassing PDrop by 9.1% and showing consistent gains on standard VLM benchmarks and autonomous driving. </span></p>
</div>


<h4 id="Online-Segment-Any-3D-Thing-as-Instance-Tracking-NeurIPS-2025-First-Author-Code"><a href="#Online-Segment-Any-3D-Thing-as-Instance-Tracking-NeurIPS-2025-First-Author-Code" class="headerlink" title="Online Segment Any 3D Thing as Instance Tracking | NeurIPS 2025 | First Author | Code"></a><a href="">Online Segment Any 3D Thing as Instance Tracking</a> | NeurIPS 2025 | <em>First Author</em> | <a href="">Code</a></h4><div style="overflow:auto; margin:24px 0;">
  <!-- 1. 浮动图片 -->
  <img
    src="paper_imgs/AutoSAM.png"
    alt="MambaFusion"
    style="
      float: left;
      width: 200px;
      margin: 0 16px 16px 0;
      object-fit: contain;
    "
  />


<p>  <span style="margin-right:24px;"> <strong>Motivation:</strong> Online 3D instance segmentation with VFMs often yields fragmented masks, over segmentation, and identity drift because streaming pipelines lack instance level temporal modeling. <strong>Method:</strong> We recast the task as tracking and add three lightweight modules. LTM maintains a bounded track bank with confidence gated Hungarian assignment to recover identities through occlusion. STM applies distance aware cross frame attention to inject short term context while filtering background. SCL merges high affinity fragments by joint 2D and 3D reasoning and uses one to many supervision to produce coherent queries for LTM and STM. <strong>Results:</strong> On ScanNet200 our method improves ESAM by 2.8 AP while retaining real time throughput and shows consistent gains on ScanNet SceneNN and 3RScan. </span></p>
</div>



<h4 id="MambaFusion-Height-Fidelity-Dense-Global-Fusion-for-Multi-modal-3D-Object-Detection-ICCV-2025-Highlight-First-Author-Code"><a href="#MambaFusion-Height-Fidelity-Dense-Global-Fusion-for-Multi-modal-3D-Object-Detection-ICCV-2025-Highlight-First-Author-Code" class="headerlink" title="MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection | ICCV 2025 Highlight!| First Author | Code"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.04369">MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection</a> | ICCV 2025 <span style="color:red">Highlight!</span>| <em>First Author</em> | <a target="_blank" rel="noopener" href="https://github.com/AutoLab-SAI-SJTU/MambaFusion">Code</a></h4><div style="overflow:auto; margin:24px 0;">
  <!-- 1. 浮动图片 -->
  <img
    src="paper_imgs/mambafusion.png"
    alt="MambaFusion"
    style="
      float: left;
      width: 200px;
      margin: 0 16px 16px 0;
      object-fit: contain;
    "
  />


  <span style="margin-right:24px;">
    <strong>Motivation:</strong> In camera + LiDAR multi-modal 3D detection, current methods struggle to achieve efficiency, long-range modeling, and full scene information retention simultaneously. <strong>Method:</strong> Inspired by linear-attention mechanisms, we propose the first efficient, set-based fusion strategy using linear attention to balance speed, range, and completeness in camera–LiDAR detection. We perform qualitative and quantitative analyses to select the Mamba attention module for our main experiments. By combining Height-Fidelity LiDAR encoding with a Hybrid Mamba Block, we align modalities while preserving height cues and learning both local and global context. <strong>Results:</strong> On the nuScenes validation set, we achieve an NDS of 75.0, surpassing SOTA methods that rely on sampled-resolution inputs and deliver faster inference.
  </span>

</div>

<hr>
<h4 id="A-Teacher-Asymmetric-Network-for-3D-Semi-Supervised-Object-Detection-CVPR-2024-First-Author"><a href="#A-Teacher-Asymmetric-Network-for-3D-Semi-Supervised-Object-Detection-CVPR-2024-First-Author" class="headerlink" title="A-Teacher: Asymmetric Network for 3D Semi-Supervised Object Detection | CVPR 2024 | First Author"></a><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_A-Teacher_Asymmetric_Network_for_3D_Semi-Supervised_Object_Detection_CVPR_2024_paper.pdf">A-Teacher: Asymmetric Network for 3D Semi-Supervised Object Detection</a> | CVPR 2024 | <em>First Author</em></h4><div style="overflow:auto; margin:24px 0;">
  <!-- 1. 浮动图片 -->
  <img
    src="paper_imgs/a_teacher.png"
    alt="A-Teacher"
    style="
      float: left;
      width: 200px;
      margin: 0 16px 16px 0;
      object-fit: contain;
    "
  />

  <span style="margin-right:24px;">
    <strong>Motivation:</strong> Existing methods require the teacher and student models to share identical architectures and input formats, which weakens knowledge distillation and under-utilizes temporal information. <strong>Method:</strong> We introduce the first online asymmetric semi-supervised 3D detection framework that breaks the constraints of structural/input-format consistency. An attention-based refinement module is integrated, and past/future temporal cues are leveraged in a divide-and-conquer strategy to correct poor detections, missed objects, and false positives. <strong>Results:</strong> On the Waymo dataset, our approach boosts mAP (L1) by 4.7 points over the previous SOTA while requiring fewer training resources.
  </span>
</div>

<hr>
<h4 id="The-Devil-is-in-the-Quality-Exploring-Informative-Samples-for-Semi-Supervised-Monocular-3D-Object-Detection-ICRA-2025-Co-First-Author"><a href="#The-Devil-is-in-the-Quality-Exploring-Informative-Samples-for-Semi-Supervised-Monocular-3D-Object-Detection-ICRA-2025-Co-First-Author" class="headerlink" title="The Devil is in the Quality: Exploring Informative Samples for Semi-Supervised Monocular 3D Object Detection | ICRA 2025 | Co-First Author"></a><a href="#">The Devil is in the Quality: Exploring Informative Samples for Semi-Supervised Monocular 3D Object Detection</a> | ICRA 2025 | <em>Co-First Author</em></h4><div style="overflow:auto; margin:24px 0;">
  <!-- 1. 浮动图片 -->
  <img
    src="paper_imgs/aug_cri.png"
    alt="Augment-Criticize"
    style="
      float: left;
      width: 200px;
      margin: 0 16px 16px 0;
      object-fit: contain;
    "
  />

  <span style="margin-right:24px;">
    <strong>Motivation:</strong> Semi-supervised monocular 3D detection suffers from noisy pseudo-labels and low learning efficiency due to the lack of high-quality unlabeled samples. <strong>Method:</strong> We introduce an Augment-Criticizestrategy that automatically learns image transformations and aggregates predictions to mine more reliable pseudo-labels. A Critical Retraining Strategy (CRS)dynamically evaluates pseudo-label contributions during training to suppress noisy samples. <strong>Results:</strong> Applied to MonoDLE and MonoFlex, our approach yields significant performance gains, demonstrating its effectiveness and generality.
  </span>
</div>

<!-- ---

### HDGS: Hierarchical Dynamic Gaussian for Urban Driving Scenes | (AAAI 2025) | *Third Author*
- **Motivation:** Dynamic 3D Gaussian Splatting faces a fundamental trade-off between high fidelity and storage overhead in urban driving scenarios.  
- **Method:** We propose a **Hierarchical Dynamic Gaussian Splatting (HDGS)** framework that achieves efficient, high-fidelity storage compression for dynamic scenes. A multi-layer anchor structure enables fine-grained modeling of moving objects while enforcing global–local and depth consistency constraints.  
- **Results:** HDGS reduces storage overhead by an average of 62% and outperforms existing dynamic 3D Gaussian Splatting methods in rendering fidelity. -->

<h2 id="Competition"><a href="#Competition" class="headerlink" title="Competition"></a>Competition</h2><p>[2025.10] 🎉We achieved Top 3 rankings in Roboscene2025’s “Driving with Language” Track.</p>
<h2 id="Miscellanea"><a href="#Miscellanea" class="headerlink" title="Miscellanea"></a>Miscellanea</h2><p>Conference Reviewer: ICCV, NeurIPS, AAAI, ICLR.</p>
</div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/hanshiwang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Hanshi Wang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">1</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/AutoLab-SAI-SJTU/MambaFusion"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Feel free to drop me an email if you have questions about our work  
or are interested in cooperation.<br>
<a href="mailto:hanshi.wang.cv@outlook.com">Email: hanshi.wang.cv@outlook.com</a>
</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/07/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-07T13:16:02.967Z" title="Created 2025-07-07 21:16:02">2025-07-07</time></div></div></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>Archives</span>
      
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/07/">
            <span class="card-archive-list-date">
              July 2025
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Website Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article Count :</div><div class="item-count">1</div></div><div class="webinfo-item"><div class="item-name">Unique Visitors :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Page Views :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Update :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-10-27T03:16:10.371Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By Hanshi Wang</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.1</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async src="https://cdn.jsdelivr.net/npm/busuanzi@2.3.0/bsz.pure.mini.js"></script></div></body></html>